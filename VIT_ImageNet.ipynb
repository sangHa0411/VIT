{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Vision Transformer ImageNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM15DQGKDqMPeGClh38AHG6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AVYLZvszg6q","executionInfo":{"elapsed":295,"status":"ok","timestamp":1632579428528,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"},"user_tz":-540},"outputId":"849138c4-bfd0-40db-ae4b-1464a4480058"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"iP9qmGF50CRD"},"source":["import os\n","import sys\n","import copy\n","import numpy as np\n","import random\n","import multiprocessing\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fL0t26SV0Fmn"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsc9hM6L0H9b","executionInfo":{"status":"ok","timestamp":1632580059222,"user_tz":-540,"elapsed":907,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DCaeYMve5GM"},"source":["import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uUdoBdLD0KZq"},"source":["## Image Data"]},{"cell_type":"code","metadata":{"id":"v5a5_sbV0t3X"},"source":["data_path = './drive/MyDrive/Model/Data/ImageNet/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkuUqW1Z6-LI"},"source":["def read_data(dir_path, size) :\n","    img_data = []\n","    label_data = []\n","    for i in tqdm(range(1, size+1)) :\n","        file_path = dir_path + 'train_data_batch_'+str(i)\n","        data_dict = np.load(file_path, allow_pickle=True)\n","\n","        img_idx = data_dict['data']\n","        img_idx = img_idx.reshape(-1, 64, 64, 3)\n","        img_idx = np.transpose(img_idx , (0, 3, 1, 2))\n","        label_idx = data_dict['labels']\n","\n","        img_data.append(img_idx)\n","        label_data.extend(label_idx)\n","\n","    img_data = np.vstack(img_data)\n","    label_data = np.array(label_data)\n","\n","    return img_data, label_data        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UipafWxiEasu","outputId":"a75fcd37-8255-4b78-e1c2-e2ab61ad0307"},"source":["train_image, train_label = read_data(data_path, 3)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [01:04<00:00, 21.53s/it]\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"soUoFF08tUYX","outputId":"53c1b9fe-a9e3-41c2-a24a-bd0b87001052"},"source":["print('Train Data Shape \\n') \n","\n","print('Image Shape : {}'.format(train_image.shape))\n","print('Label Shape : {}'.format(train_label.shape))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Train Data Shape \n","\n","Image Shape : (384348, 3, 64, 64)\n","Label Shape : (384348,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"21_0eet-QJbb"},"source":["val_data = np.load(data_path+'val_data' , allow_pickle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"vYv8Hd8-QJiv"},"source":["val_image = val_data['data'].reshape(-1, 64, 64, 3)\n","val_image = np.transpose(val_image, (0, 3, 1, 2))\n","val_label = np.array(val_data['labels'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"QCApFK-JQJxM","outputId":"e7aa1027-7244-4afe-e75a-085fc3c1cd7a"},"source":["print('Validation Data Shape \\n') \n","\n","print('Image Shape : {}'.format(val_image.shape))\n","print('Label Shape : {}'.format(val_label.shape))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Validation Data Shape \n","\n","Image Shape : (50000, 3, 64, 64)\n","Label Shape : (50000,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6MhJATOiR4_V"},"source":["## Dataset & Dataloader"]},{"cell_type":"code","metadata":{"id":"0a_Q1t1QQJ6z","executionInfo":{"status":"ok","timestamp":1632579536838,"user_tz":-540,"elapsed":394,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["class ImageDataset(Dataset) :\n","    def __init__(self , data , label, class_size) :\n","        super(ImageDataset , self).__init__()\n","        self.data = data\n","        self.label = np.eye(class_size)[label-1]\n","\n","    def __len__(self) :\n","        data_len = self.data.shape[0]\n","        return data_len\n","\n","    def __getitem__(self , idx) :\n","        img_data = self.data[idx]\n","        img_label = self.label[idx]\n","        return img_data , img_label\n","\n","class TrainTransforms :\n","    def __init__(self, org_size, tar_size) :\n","        self.org_size = org_size\n","        self.tar_size = tar_size\n","        self.transform = transforms.Compose([\n","            transforms.Resize(org_size),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomCrop(tar_size),\n","        ])\n","\n","    def __call__(self, img_tensor) :\n","        return self.transform(img_tensor)\n","\n","class ValTransforms :\n","    def __init__(self, tar_size) :\n","        self.tar_size = tar_size\n","        self.transform = transforms.Compose([\n","            transforms.Resize(tar_size),\n","            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n","        ])\n","\n","    def __call__(self, img_tensor) :\n","        return self.transform(img_tensor)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_q7tdbvSr_m","executionInfo":{"status":"ok","timestamp":1632579537369,"user_tz":-540,"elapsed":5,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["class CutMix :\n","    def __init__(self, img_height, img_width):\n","        self.h = img_height\n","        self.w = img_width \n","        self.gen = torch.distributions.beta.Beta(1,1)\n","        \n","    def __call__(self, a_image, a_label):\n","        batch_size = a_image.shape[0]\n","        rand = torch.randperm(batch_size)\n","        b_image = a_image[rand]\n","        b_label = a_label[rand]\n","        \n","        y = torch.randint(self.h, (1,))[0]\n","        x = torch.randint(self.w, (1,))[0]\n","\n","        r = self.gen.sample()\n","        h = (self.h * torch.sqrt(1-r)).int()\n","        w = (self.w * torch.sqrt(1-r)).int()\n","        c_image = copy.deepcopy(a_image)\n","        c_image[: , : , y:y+h , x:x+w] = b_image[: , : ,y:y+h , x:x+w]\n","\n","        c_label = a_label * r + b_label * (1-r)\n","        return c_image, c_label"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYt7nFeHSMr7","executionInfo":{"status":"ok","timestamp":1632579538368,"user_tz":-540,"elapsed":8,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["class_size = 1000\n","batch_size = 128\n","org_size = 256\n","img_size = 224"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ioHb69hwQKET","executionInfo":{"status":"ok","timestamp":1632579540866,"user_tz":-540,"elapsed":2041,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["train_dset = ImageDataset(train_image, train_label, class_size)\n","train_loader = DataLoader(train_dset, \n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=multiprocessing.cpu_count()//2)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"eRq7ta77SboI","executionInfo":{"status":"ok","timestamp":1632579540868,"user_tz":-540,"elapsed":50,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["val_dset = ImageDataset(val_image, val_label, class_size)\n","val_loader = DataLoader(val_dset, \n","                        batch_size=batch_size,\n","                        shuffle=True,\n","                        num_workers=multiprocessing.cpu_count()//2)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ntH3qpdSt4E","executionInfo":{"status":"ok","timestamp":1632579542106,"user_tz":-540,"elapsed":10,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["train_transform = TrainTransforms(org_size, img_size)\n","norm_transform = transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n","val_transform = ValTransforms(img_size)\n","\n","img_cutmix = CutMix(img_size, img_size)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62WS4Xlc2ps9"},"source":["## Device & Seed"]},{"cell_type":"code","metadata":{"id":"vuPCf1o82scj","executionInfo":{"status":"ok","timestamp":1632579544438,"user_tz":-540,"elapsed":270,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["def seed_everything(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","seed_everything(777)\n","use_cuda =  torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\") "],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8IWHm-koRdA2"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"-3GyTKrl4IX3","executionInfo":{"status":"ok","timestamp":1632579546494,"user_tz":-540,"elapsed":435,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["class PatchFlatten(nn.Module) :\n","    def __init__(self, ch_size, img_size, p_size) :\n","        super(PatchFlatten , self).__init__()\n","        assert img_size % p_size == 0\n","        self.ch_size = ch_size\n","        self.img_size = img_size\n","        self.p_size = p_size\n","\n","    def forward(self, img_tensor) :\n","        p_len = int(self.img_size / self.p_size)\n","        v_size = self.p_size ** 2 * self.ch_size\n","\n","        img_tensor = img_tensor.permute(0,2,3,1)\n","        img_patchs = torch.reshape(img_tensor , (-1, p_len, self.p_size, p_len, self.p_size, self.ch_size))\n","        patch_tensor = img_patchs.permute(0,1,3,2,4,5)\n","\n","        v_tensor = torch.reshape(patch_tensor , (-1, p_len, p_len, v_size))\n","        v_tensor = torch.reshape(v_tensor , (-1, p_len**2, v_size))\n","        return v_tensor\n","\n","class PositionEmbedding(nn.Module) :\n","    def __init__(self, p_len, v_size, em_dim, cuda_flag) :\n","        super(PositionEmbedding , self).__init__()\n","        self.p_len = p_len\n","        self.v_size = v_size\n","        self.em_dim = em_dim\n","        # start token \n","        cls_tensor = torch.FloatTensor(np.random.randn(1,em_dim))\n","        if cuda_flag :\n","            cls_tensor = cls_tensor.cuda()\n","        self.cls_tensor = nn.Parameter(cls_tensor, requires_grad=True)\n","        # positional encoding tensor which is trainable\n","        pos_tensor = torch.FloatTensor(np.random.randn(1 , p_len+1 , em_dim))\n","        if cuda_flag :\n","            pos_tensor = pos_tensor.cuda()\n","        self.pos_tensor = nn.Parameter(pos_tensor , requires_grad=True) #(1 , patch_len+1 , em_dim)\n","        self.pos_linear = nn.Linear(v_size , em_dim)\n","\n","    def forward(self, f_tensor) :\n","        batch_size = f_tensor.shape[0]\n","        # repeat cls tensor\n","        cls_tensor = self.cls_tensor.repeat(batch_size , 1) #(batch_size , em_dim)\n","        cls_tensor = cls_tensor.unsqueeze(1) #(batch_size , 1 , em_dim)\n","        # apply linear layer , convert vector shape patch vector size to embedding dimension\n","        x_tensor = self.pos_linear(f_tensor) #(batch_size , patch_len , em_dim)\n","        x_tensor = torch.cat([cls_tensor , x_tensor] , dim=1) #(batch_size , patch_len + 1 , em_dim)\n","        # add positional encoding to vector\n","        z_tensor = x_tensor + self.pos_tensor #(batch_size , patch_len+1 , em_dim)\n","        return z_tensor\n","\n","class MultiHeadAttention(nn.Module) :\n","    def __init__(self, sen_size,  d_model, num_heads) :\n","        super(MultiHeadAttention , self).__init__()\n","        self.sen_size = sen_size\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.depth = int(d_model / num_heads) # embedding_dim / num_heads\n","\n","        self.q_layer = nn.Linear(d_model , d_model)\n","        self.k_layer = nn.Linear(d_model , d_model)\n","        self.v_layer = nn.Linear(d_model , d_model)\n","        self.o_layer = nn.Linear(d_model , d_model)\n","\n","        self.scale = torch.sqrt(torch.tensor(self.depth , dtype=torch.float32 , requires_grad=False))\n","\n","    def split(self , tensor) :\n","        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.num_heads , self.depth)) # (batch_size , sen_size , num_heads , depth)\n","        tensor = torch.transpose(tensor , 1 , 2) # batch_size , num_heads , sen_size , depth)\n","        return tensor\n","\n","    def merge(self , tensor) :\n","        tensor = torch.transpose(tensor , 1 , 2) # (batch_size , sen_size , num_heads , depth)\n","        tensor = torch.reshape(tensor , (-1 , self.sen_size , self.d_model)) # (batch_size , sen_size , embedding_dim)\n","        return tensor\n","\n","    def scaled_dot_production(self, q_tensor, k_tensor, v_tensor, m_tensor) :\n","        q_tensor = self.split(q_tensor)\n","        k_tensor = self.split(k_tensor)\n","        v_tensor = self.split(v_tensor)\n","        k_tensor_T = torch.transpose(k_tensor , 2 , 3) # (batch_size , num_heads , depth , sen_size)\n","\n","        qk_tensor = torch.matmul(q_tensor , k_tensor_T) # (batch_size , num_heads , sen_size , sen_size)\n","        qk_tensor /= self.scale\n","        if m_tensor != None :\n","            qk_tensor -= (m_tensor * 1e+6)\n","\n","        qk_tensor = F.softmax(qk_tensor , dim = -1)\n","        att = torch.matmul(qk_tensor , v_tensor) # (batch_size , num_heads , sen_size , depth)\n","        return att\n","\n","    def forward(self, q_in, k_in, v_in, m_in) :\n","        q_tensor = self.q_layer(q_in)\n","        k_tensor = self.k_layer(k_in)\n","        v_tensor = self.v_layer(v_in)\n","\n","        att_tensor = self.scaled_dot_production(q_tensor, k_tensor, v_tensor, m_in)\n","        att_tensor = self.merge(att_tensor)\n","\n","        o_tensor = self.o_layer(att_tensor)\n","        return o_tensor\n","\n","class FeedForward(nn.Module) :\n","    def __init__(self, hidden_size, d_model) :\n","        super(FeedForward , self).__init__()\n","        self.hidden_size = hidden_size\n","        self.d_model = d_model\n","        self.ff = nn.Sequential(nn.Linear(d_model , hidden_size), \n","                                nn.ReLU(),\n","                                nn.Linear(hidden_size , d_model))\n","\n","    def forward(self, in_tensor) :\n","        o_tensor = self.ff(in_tensor)\n","        return o_tensor\n","\n","\n","class EncoderBlock(nn.Module) :\n","    def __init__(self, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate) :\n","        super(EncoderBlock , self).__init__()\n","        self.sen_size = sen_size\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.hidden_size = hidden_size\n","\n","        self.mha_layer = MultiHeadAttention(sen_size , d_model , num_heads)\n","        self.ff_layer = FeedForward(hidden_size , d_model)\n","\n","        self.drop1_layer = nn.Dropout(drop_rate)\n","        self.norm1_layer = nn.LayerNorm(d_model , eps=norm_rate)\n","        self.drop2_layer = nn.Dropout(drop_rate)\n","        self.norm2_layer = nn.LayerNorm(d_model , eps=norm_rate)\n","\n","    def forward(self, in_tensor) :\n","        mha_tensor = self.mha_layer(in_tensor, in_tensor, in_tensor, None)\n","        mha_tensor = self.drop1_layer(mha_tensor)\n","        h_tensor = self.norm1_layer(in_tensor + mha_tensor) # residual connection\n","\n","        ff_tensor = self.ff_layer(h_tensor)\n","        ff_tensor = self.drop2_layer(ff_tensor)\n","        o_tensor = self.norm2_layer(h_tensor + ff_tensor)\n","        return o_tensor\n","\n","class Encoder(nn.Module) :\n","    def __init__(self, layer_size, sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate) :\n","        super(Encoder , self).__init__()\n","        self.layer_size = layer_size\n","    \n","        self.en_net = nn.Sequential()\n","        for i in range(layer_size) :\n","            en_block = EncoderBlock(sen_size, d_model, num_heads, hidden_size, drop_rate, norm_rate)\n","            self.en_net.add_module('Encoder_Block' + str(i) , en_block)\n","\n","    def forward(self, in_tensor) :\n","        o_tensor = self.en_net(in_tensor)\n","        return o_tensor\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"twaLo3dF8AcD","executionInfo":{"status":"ok","timestamp":1632580319605,"user_tz":-540,"elapsed":423,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["class VIT(nn.Module) :\n","    def __init__(self , \n","        layer_size , \n","        class_size , \n","        channel_size , \n","        img_size , \n","        patch_size , \n","        em_dim , \n","        num_heads , \n","        hidden_size , \n","        drop_rate , \n","        norm_rate , \n","        cuda_flag) :\n","        super(VIT , self).__init__()\n","\n","        self.class_size = class_size\n","        self.img_size = img_size\n","        self.patch_size = patch_size\n","        self.layer_size = layer_size\n","        self.em_dim = em_dim\n","        self.num_heads = num_heads\n","        self.hidden_size = hidden_size\n","        self.drop_rate = drop_rate \n","        self.norm_rate = norm_rate\n","        self.cuda_flag = cuda_flag\n","        \n","\n","        p_len = int(img_size / patch_size) ** 2\n","        v_size = (patch_size ** 2) * channel_size\n","        self.p_flatten = PatchFlatten(channel_size, img_size, patch_size)\n","        self.p_embedding = PositionEmbedding(p_len, v_size, em_dim, cuda_flag)\n","        self.encoder = Encoder(layer_size, p_len+1, em_dim, num_heads, hidden_size, drop_rate, norm_rate)\n","\n","        self.o_layer = nn.Linear(em_dim, class_size)\n","\n","        self.init_param()\n","\n","    # Xavier Initialization\n","    def init_param(self) :\n","        for p in self.parameters() :\n","            if p.dim() > 1 :\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward(self, tensor) :\n","        f_tensor = self.p_flatten(tensor) # patch faltten\n","        em_tensor = self.p_embedding(f_tensor) # positional embedding\n","        o_tensor = self.encoder(em_tensor)\n","\n","        index = torch.tensor([0])\n","\n","        if self.cuda_flag == True :\n","            index = index.cuda()\n","\n","        idx_tensor = torch.index_select(o_tensor, 1 , index)\n","        idx_tensor = idx_tensor.squeeze(1)\n","        rep_tensor = self.o_layer(idx_tensor)\n","        return rep_tensor"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io6FGcuFRYzz"},"source":["## Acc & Loss function"]},{"cell_type":"code","metadata":{"id":"tLKaroqkROqn","executionInfo":{"status":"ok","timestamp":1632580322233,"user_tz":-540,"elapsed":628,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["def acc_fn(y_output , y_label) :\n","    y_acc = (torch.argmax(y_output, dim = -1) == torch.argmax(y_label, dim = -1)).float()    \n","    y_acc = torch.mean(y_acc)\n","    return y_acc\n","\n","def loss_fn(y_output, y_label) :\n","    y_log = -F.log_softmax(y_output, -1)\n","    y_loss = torch.mul(y_log, y_label)\n","    y_sum = torch.sum(y_loss, dim=1)\n","    y_mean = torch.mean(y_sum)\n","    return y_mean"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sfpJ_UXdTW0I"},"source":["## Hyperparameter"]},{"cell_type":"code","metadata":{"id":"4SjkOYHQTXMw","executionInfo":{"status":"ok","timestamp":1632580324592,"user_tz":-540,"elapsed":320,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["# VIT Base/16\n","layer_size = 12\n","channel_size = 3\n","patch_size = 32\n","embedding_dim = 768\n","hidden_size = 3072\n","num_heads = 12\n","drop_rate = 1e-1\n","norm_rate = 1e-6"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZmTxMZfTnFO","executionInfo":{"status":"ok","timestamp":1632580326552,"user_tz":-540,"elapsed":1356,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["model = VIT(layer_size, \n","            class_size, \n","            channel_size, \n","            img_size, \n","            patch_size, \n","            embedding_dim, \n","            num_heads, \n","            hidden_size,\n","            drop_rate, \n","            norm_rate, \n","            use_cuda).to(device)"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VE7vnI65WVcI"},"source":["## Logging"]},{"cell_type":"code","metadata":{"id":"cs1gLRBVWVqF","executionInfo":{"status":"ok","timestamp":1632580075805,"user_tz":-540,"elapsed":5031,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["dir_path = '/content/drive/MyDrive/Model/CV/ImageClassification/VIT'\n","\n","writer = SummaryWriter(os.path.join(dir_path, 'Log'))"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jxQeBwVqTQSl"},"source":["## Optimizer & Scheduler"]},{"cell_type":"code","metadata":{"id":"ROkk3NmpNFIu","executionInfo":{"status":"ok","timestamp":1632580332056,"user_tz":-540,"elapsed":260,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["warmup_steps = 2000\n","\n","def schedule_fn(epoch , lr) :\n","    step_num = epoch + 1\n","    d_model = embedding_dim\n","    arg1 = d_model ** (-0.5)\n","    arg2 = min(step_num**(-0.5) , (step_num * warmup_steps**(-1.5)))\n","    return (arg1 * arg2)/lr"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"n80WUd2GLqSW","executionInfo":{"status":"ok","timestamp":1632580333354,"user_tz":-540,"elapsed":6,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["dumb_lr = 1e-4\n","\n","optimizer = optim.Adam(model.parameters() , lr = dumb_lr , betas = (0.9,0.999) , weight_decay = 0.1)\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch : schedule_fn(epoch,dumb_lr))"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-ZjdqVmCVHC","executionInfo":{"status":"ok","timestamp":1632580334494,"user_tz":-540,"elapsed":7,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["def progressLearning(value, endvalue, loss, acc, bar_length=50):\n","    percent = float(value + 1) / endvalue\n","    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n","    spaces = ' ' * (bar_length - len(arrow))\n","    sys.stdout.write(\"\\r[{0}] {1}/{2} \\t Loss : {3:.3f} , Acc : {4:.3f}\".format(arrow + spaces, value+1, endvalue, loss, acc))\n","    sys.stdout.flush()"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeW3k7qIVZGn","executionInfo":{"status":"ok","timestamp":1632580335787,"user_tz":-540,"elapsed":416,"user":{"displayName":"박상하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05369925220722100974"}}},"source":["min_loss = np.inf\n","epochs = 100\n","stop_count = 0\n","log_count = 0"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ux1WQ8ajJtrk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2554fc58-23b2-431a-bc6f-3a09f359367d"},"source":["for epoch in range(epochs) :\n","    idx = 0\n","    model.train()\n","    print('Epoch : %d/%d \\t Learning Rate : %e' %(epoch, epochs, optimizer.param_groups[0][\"lr\"]))\n","    # training process\n","    for img_data, img_label in train_loader :\n","        img_data = img_data.float().to(device) / 255\n","        img_label = img_label.to(device)\n","\n","        optimizer.zero_grad()\n","            \n","        img_data = train_transform(img_data)\n","        img_data, img_label = img_cutmix(img_data, img_label)\n","        img_data = norm_transform(img_data)\n","        img_out = model(img_data)\n","        \n","        loss = loss_fn(img_out, img_label)\n","        acc = acc_fn(img_out, img_label)\n","\n","        loss.backward()\n","        optimizer.step()\n","        \n","        progressLearning(idx, len(train_loader), loss.item(), acc.item())\n","\n","        if (idx + 1) % 100 == 0 :\n","            writer.add_scalar('train/loss', loss.item(), log_count)\n","            writer.add_scalar('train/acc', acc.item(), log_count)\n","            log_count += 1\n","        idx += 1\n","\n","    # validation process\n","    with torch.no_grad() :\n","        model.eval()\n","        loss_eval = 0.0\n","        acc_eval = 0.0\n","        for img_data, img_label in val_loader :\n","            img_data = img_data.float().to(device) / 255\n","            img_label = img_label.to(device)\n","\n","            img_data = val_transform(img_data)\n","            img_out = model(img_data)\n","        \n","            loss_eval += loss_fn(img_out, img_label)\n","            acc_eval += acc_fn(img_out, img_label)\n","\n","        loss_eval /= len(val_loader)\n","        acc_eval /= len(val_loader)\n","\n","    writer.add_scalar('val/loss', loss_eval.item(), epoch)\n","    writer.add_scalar('val/acc', acc_eval.item(), epoch)\n","    \n","    if loss_eval < min_loss :\n","        min_loss = loss_eval\n","        torch.save({'epoch' : (epoch) ,  \n","            'model_state_dict' : model.state_dict() , \n","            'loss' : loss_eval.item() , \n","            'acc' : acc_eval.item()} , \n","            os.path.join(dir_path, 'Model', 'vit_model.pt'))        \n","        stop_count = 0 \n","    else :\n","        stop_count += 1\n","        if stop_count >= 5 :      \n","            print('\\tTraining Early Stopped')\n","            break\n","            \n","    scheduler.step()\n","    print('\\nTest Loss : %.3f \\t Test Accuracy : %.3f\\n' %(loss_eval, acc_eval))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0/100 \t Learning Rate : 4.034358e-07\n","[->                                                ] 134/3003 \t Loss : 7.298 , Acc : 0.000"]}]},{"cell_type":"code","metadata":{"id":"8A-A_31oW5Wf"},"source":[""],"execution_count":null,"outputs":[]}]}